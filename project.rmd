---
title: "Stat 435 Project"
author: "Zach Fechko (011711215) & Anthony Ghimpu ()"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output:
    html_document:
        theme: spacelab
        highlight: tango
        toc: true
        toc_float: true
---

***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r label=imports, message=FALSE}
library(MASS)
library(ggplot2)
library(glmnet)
attach(Boston)
```

## Aspects of the Data
```{r label=aspects}
str(Boston)
names(Boston)
dim(Boston)
```

## Task 2

```{r label=task2}
#randomly split the data into 2 sets, 80% for training and 20% for testing
#train set is used for fitting linear model
#test set is used for evaluating the model

set.seed(1)
train <- sample(1:nrow(Boston), 0.8*nrow(Boston))
test <- (-train)

#fit linear model
lm.fit <- lm(medv ~ ., data = Boston, subset = train)
summary(lm.fit)
```

## Task 3

```{r label=task3}
library(caret)
#Implement Lasso Regression
#Use 10-fold cross validation to select the best tuning parameter lambda
#Use the best lambda to fit the model on the training set
#Use the model to predict the response on the test set
#Conduct hypothesis testing to determine which predictors are significant

#10-fold cross validation
set.seed(1)
ctrl <- trainControl(method = "cv", number = 10)
lassoGrid <- expand.grid(alpha = 1, lambda = seq(0.001, 0.1, length = 100))
lassoFit <- train(medv ~ ., data = Boston, method = "glmnet", trControl = ctrl, tuneGrid = lassoGrid, subset = train)
lassoFit
```

```{r label=task3.1}
#best lambda
lassoFit$bestTune

#fit model on training set
lassoFit$finalModel

#predict response on test set
lassoPred <- predict(lassoFit, newdata = Boston[test,])
lassoPred

#hypothesis testing
#null hypothesis: coefficient = 0
#alternative hypothesis: coefficient != 0
#p-value < 0.05: reject null hypothesis
#p-value > 0.05: fail to reject null hypothesis
#p-value = 0: reject null hypothesis

```

## Task 4

```{r label=task4}

```